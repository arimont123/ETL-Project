{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596170711976",
   "display_name": "Python 3.8.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Web scraping imports \n",
    "from bs4 import BeautifulSoup as bs \n",
    "from selenium import webdriver\n",
    "import time \n",
    "\n",
    "#Random import \n",
    "import numpy as np\n",
    "\n",
    "#DataFrame import\n",
    "import pandas as pd\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Current page: 1\nScape Done!!!!\n"
    }
   ],
   "source": [
    "#Code ready to pulll listings of only the main page for 20 pages ----------------------------------------\n",
    "\n",
    "#Dictionary for storage\n",
    "listings_dict = {'Price (usd)' : [], \"Address\" : [], 'Rooms' : [], 'Bathrooms' : [], 'Area (sqrt)' : [], 'Link' : []}\n",
    "\n",
    "#Path to drivers - need 2 browsers 1 for the main page listing and another for the individual links of each linsting.\n",
    "# If this is not done and we do everything in the same browser Zillow detects the crawler. \n",
    "# Remember to unzip the file of the drivers and get the absolute path to the driver not the relative path.\n",
    "#In the folder, copy the chrome driver and rename the copy as chromedriver2. Make sure browser is linked to chromedriver AND browser2 is linked to chromedriver2\n",
    "browser = webdriver.Chrome(\"/Users/Sebastian/Documents/GitHub/Data Visualization Bootcamp/Sebastian Homework/Goup Project - 2/TFH-Project/Zillow Scrapper/chromedriver\")\n",
    "#browser2 = webdriver.Chrome(\"/Users/Sebastian/Documents/GitHub/Data Visualization Bootcamp/Sebastian Homework/TFH-Project2/Zillow Scrapper/chromedriver2\")\n",
    "\n",
    "#starting page\n",
    "page = 1 \n",
    "\n",
    "#url to scrape starting at page 1\n",
    "url = \"https://www.zillow.com/homes/for_sale/fore_lt/austin_rb/pmf,pf_pt/?searchQueryState=%7B%22pagination%22%3A%7B%7D%2C%22usersSearchTerm%22%3A%22austin%22%2C%22mapBounds%22%3A%7B%22west%22%3A-98.3748184592871%2C%22east%22%3A-97.4409805686621%2C%22south%22%3A29.767357829257207%2C%22north%22%3A30.58768177330594%7D%2C%22regionSelection%22%3A%5B%7B%22regionId%22%3A10221%2C%22regionType%22%3A6%7D%5D%2C%22isMapVisible%22%3Atrue%2C%22filterState%22%3A%7B%22sort%22%3A%7B%22value%22%3A%22globalrelevanceex%22%7D%2C%22auc%22%3A%7B%22value%22%3Afalse%7D%2C%22nc%22%3A%7B%22value%22%3Afalse%7D%2C%22fsbo%22%3A%7B%22value%22%3Afalse%7D%2C%22cmsn%22%3A%7B%22value%22%3Afalse%7D%2C%22fsba%22%3A%7B%22value%22%3Afalse%7D%7D%2C%22isListVisible%22%3Atrue%7D\"\n",
    "\n",
    "#Open url -- We only want to open the browser once, so this is run outside the loop.\n",
    "browser.get(url)\n",
    "\n",
    "#while loop to iterate until condition is meet\n",
    "while True:\n",
    "\n",
    "    #Bot handler. -- Gives us 5 minutes to solve the human test and continues the code after it sees class = list-card-info.\n",
    "    try:\n",
    "        WebDriverWait(browser, 60*5).until(EC.presence_of_element_located((By.CLASS_NAME, \"list-card-info\")))\n",
    "    except:\n",
    "        print(\"Wait Timed out\")\n",
    "\n",
    "    \n",
    "\n",
    "    #Prints current page to scrape\n",
    "    print(f\"Current page: {page}\")\n",
    "\n",
    "    #Random lag generator - try to keep the code to be detected as a bot \n",
    "    lag = np.random.uniform(0, 1.5*60)\n",
    "    time.sleep(lag)\n",
    "\n",
    "    #save the html source of the main page.\n",
    "    html = browser.page_source\n",
    "\n",
    "    #Use bs4 to parse the html response.\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    #Results for all the listings in the page.\n",
    "    listings = soup.find_all('div', class_=\"list-card-info\")\n",
    "\n",
    "    #For loop to evaluate each listing per page\n",
    "    for listing in listings:\n",
    "\n",
    "        #page index counter\n",
    "        count = 0\n",
    "\n",
    "        #Defines each variable for each iteration\n",
    "        price = None \n",
    "        address = None \n",
    "        rooms = None \n",
    "        bathrooms = None \n",
    "        area = None \n",
    "        link = None \n",
    "        # typeProperty = None \n",
    "        # yearBuilt = None \n",
    "        # parking = None \n",
    "        # lot = None \n",
    "        # saleHistory = None \n",
    "        # taxHistory = None\n",
    "\n",
    "        #Try the main page.\n",
    "  \n",
    "            #Price of the property\n",
    "        try: \n",
    "            price = listing.find('div', class_=\"list-card-price\").text\n",
    "        except:\n",
    "            price = \"N/A\"\n",
    "\n",
    "            #Address\n",
    "        try: \n",
    "            address = listing.find('address', class_=\"list-card-addr\").text\n",
    "        except:\n",
    "             address = 'N/A'   \n",
    "\n",
    "            #Rooms  - some are listed as Studio, bds and bd\n",
    "        try:\n",
    "            rooms = listing.find_all('li')[0].text\n",
    "        except:\n",
    "            rooms = \"N/A\" \n",
    "\n",
    "            #Bathrooms\n",
    "        try:\n",
    "            bathrooms = listing.find_all('li')[1].text\n",
    "        except:\n",
    "            bathrooms = \"N/A\"\n",
    "            #Area of the house.\n",
    "        try:  \n",
    "            area = listing.find_all('li')[2].text.replace(\" sqft\",\"\")\n",
    "        except: \n",
    "            area = \"N/A\"\n",
    "            #link of the individual listing.\n",
    "        try:\n",
    "            link = listing.a['href']\n",
    "        except:\n",
    "             link = \"N/A\"   \n",
    "\n",
    "        #Only appends listings with complete information\n",
    "        if (price and address and rooms and bathrooms and area and link):\n",
    "\n",
    "            listingInformation = [price, address, rooms, bathrooms, area, link]\n",
    "\n",
    "            #For loop to append the scraped information.\n",
    "            for key,info in zip(listings_dict.keys(), listingInformation):\n",
    "                listings_dict[key].append(info)\n",
    "\n",
    "        #Adds 1 to the count at the end of the listing scrape\n",
    "        count += 1\n",
    "            \n",
    "\n",
    "    #Adds 1 to the page counter\n",
    "    page += 1\n",
    "\n",
    "    #Finds elements to go next page\n",
    "    try:\n",
    "        nextpage = browser.find_element_by_css_selector(\"a.Button-wpcbcc-0.lcWnHB.PaginationButton-si2hz6-0.cUjspl\")\n",
    "    except:\n",
    "        browser.quit()\n",
    "        #browser2.quit()\n",
    "        print(\"Scape Done!!!!\")\n",
    "        break\n",
    "\n",
    "    #Zillow only loads 20 page (500 listings) at  time.\n",
    "    if page <= 1:\n",
    "        #clicks next page.\n",
    "        nextpage.click()\n",
    "        #Random lag generator - try to keep the code to be detected as a bot \n",
    "        lag = np.random.uniform(0, 1.5*60)\n",
    "        time.sleep(lag)\n",
    "\n",
    "    else:\n",
    "        #When the code is done, this code kills the driver.\n",
    "        browser.quit()\n",
    "        #browser2.quit()\n",
    "        print(\"Scape Done!!!!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        Price (usd)                                  Address           Rooms  \\\n0          $232,800       4704 Manchaca Rd, Austin, TX 78745           3 bds   \n1   Est. $1,087,650        806 Bouldin Ave, Austin, TX 78704           4 bds   \n2     Est. $438,311         2013 Shiloh Dr, Austin, TX 78745          -- bds   \n3               $--          4609 Duval St, Austin, TX 78751            1 bd   \n4     Est. $228,512          12412 Tay Ter, Austin, TX 78754           3 bds   \n5     Est. $540,083    5210 Joe Sayers Ave, Austin, TX 78756            1 bd   \n6     Est. $175,865      604 Montopolis Dr, Austin, TX 78741            1 bd   \n7     Est. $463,516       5503 Ameswood Dr, Austin, TX 78723           3 bds   \n8     Est. $565,378        5307 Harmon Ave, Austin, TX 78751           3 bds   \n9     Est. $434,780          702 Zennia St, Austin, TX 78751          -- bds   \n10    Est. $294,866          5005 Lott Ave, Austin, TX 78721          -- bds   \n11    Est. $298,328  1614 Cripple Creek Dr, Austin, TX 78758           4 bds   \n12              $--       5507 Hudson Holw, Austin, TX 78759           4 bds   \n13              $--        3604 Robbins Rd, Austin, TX 78730  1.03 acres lot   \n14    Est. $401,581       7407 W Gate Blvd, Austin, TX 78745           4 bds   \n\n   Bathrooms Area (sqrt)                                               Link  \n0       2 ba       1,657  https://www.zillow.com/homedetails/4704-Mancha...  \n1       3 ba       2,564  https://www.zillow.com/homedetails/806-Bouldin...  \n2      -- ba       2,140  https://www.zillow.com/homedetails/2013-Shiloh...  \n3       1 ba         513  https://www.zillow.com/homedetails/4609-Duval-...  \n4       2 ba       1,203  https://www.zillow.com/homedetails/12412-Tay-T...  \n5       1 ba         850  https://www.zillow.com/homedetails/5210-Joe-Sa...  \n6       1 ba         864  https://www.zillow.com/homedetails/604-Montopo...  \n7       2 ba       2,120  https://www.zillow.com/homedetails/5503-Ameswo...  \n8       2 ba       1,551  https://www.zillow.com/homedetails/5307-Harmon...  \n9      -- ba         874  https://www.zillow.com/homedetails/702-Zennia-...  \n10      1 ba         880  https://www.zillow.com/homedetails/5005-Lott-A...  \n11      2 ba       1,501  https://www.zillow.com/homedetails/1614-Crippl...  \n12    2.5 ba       2,488  https://www.zillow.com/homedetails/5507-Hudson...  \n13       N/A         N/A  https://www.zillow.com/homedetails/3604-Robbin...  \n14      2 ba       1,598  https://www.zillow.com/homedetails/7407-W-Gate...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Price (usd)</th>\n      <th>Address</th>\n      <th>Rooms</th>\n      <th>Bathrooms</th>\n      <th>Area (sqrt)</th>\n      <th>Link</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>$232,800</td>\n      <td>4704 Manchaca Rd, Austin, TX 78745</td>\n      <td>3 bds</td>\n      <td>2 ba</td>\n      <td>1,657</td>\n      <td>https://www.zillow.com/homedetails/4704-Mancha...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Est. $1,087,650</td>\n      <td>806 Bouldin Ave, Austin, TX 78704</td>\n      <td>4 bds</td>\n      <td>3 ba</td>\n      <td>2,564</td>\n      <td>https://www.zillow.com/homedetails/806-Bouldin...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Est. $438,311</td>\n      <td>2013 Shiloh Dr, Austin, TX 78745</td>\n      <td>-- bds</td>\n      <td>-- ba</td>\n      <td>2,140</td>\n      <td>https://www.zillow.com/homedetails/2013-Shiloh...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>$--</td>\n      <td>4609 Duval St, Austin, TX 78751</td>\n      <td>1 bd</td>\n      <td>1 ba</td>\n      <td>513</td>\n      <td>https://www.zillow.com/homedetails/4609-Duval-...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Est. $228,512</td>\n      <td>12412 Tay Ter, Austin, TX 78754</td>\n      <td>3 bds</td>\n      <td>2 ba</td>\n      <td>1,203</td>\n      <td>https://www.zillow.com/homedetails/12412-Tay-T...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Est. $540,083</td>\n      <td>5210 Joe Sayers Ave, Austin, TX 78756</td>\n      <td>1 bd</td>\n      <td>1 ba</td>\n      <td>850</td>\n      <td>https://www.zillow.com/homedetails/5210-Joe-Sa...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Est. $175,865</td>\n      <td>604 Montopolis Dr, Austin, TX 78741</td>\n      <td>1 bd</td>\n      <td>1 ba</td>\n      <td>864</td>\n      <td>https://www.zillow.com/homedetails/604-Montopo...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Est. $463,516</td>\n      <td>5503 Ameswood Dr, Austin, TX 78723</td>\n      <td>3 bds</td>\n      <td>2 ba</td>\n      <td>2,120</td>\n      <td>https://www.zillow.com/homedetails/5503-Ameswo...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Est. $565,378</td>\n      <td>5307 Harmon Ave, Austin, TX 78751</td>\n      <td>3 bds</td>\n      <td>2 ba</td>\n      <td>1,551</td>\n      <td>https://www.zillow.com/homedetails/5307-Harmon...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Est. $434,780</td>\n      <td>702 Zennia St, Austin, TX 78751</td>\n      <td>-- bds</td>\n      <td>-- ba</td>\n      <td>874</td>\n      <td>https://www.zillow.com/homedetails/702-Zennia-...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Est. $294,866</td>\n      <td>5005 Lott Ave, Austin, TX 78721</td>\n      <td>-- bds</td>\n      <td>1 ba</td>\n      <td>880</td>\n      <td>https://www.zillow.com/homedetails/5005-Lott-A...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Est. $298,328</td>\n      <td>1614 Cripple Creek Dr, Austin, TX 78758</td>\n      <td>4 bds</td>\n      <td>2 ba</td>\n      <td>1,501</td>\n      <td>https://www.zillow.com/homedetails/1614-Crippl...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>$--</td>\n      <td>5507 Hudson Holw, Austin, TX 78759</td>\n      <td>4 bds</td>\n      <td>2.5 ba</td>\n      <td>2,488</td>\n      <td>https://www.zillow.com/homedetails/5507-Hudson...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>$--</td>\n      <td>3604 Robbins Rd, Austin, TX 78730</td>\n      <td>1.03 acres lot</td>\n      <td>N/A</td>\n      <td>N/A</td>\n      <td>https://www.zillow.com/homedetails/3604-Robbin...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Est. $401,581</td>\n      <td>7407 W Gate Blvd, Austin, TX 78745</td>\n      <td>4 bds</td>\n      <td>2 ba</td>\n      <td>1,598</td>\n      <td>https://www.zillow.com/homedetails/7407-W-Gate...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "listings_df = pd.DataFrame(listings_dict)\n",
    "\n",
    "listings_df.to_csv('zillowOuput.csv')\n",
    "\n",
    "listings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Current page: 1\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-992b79e8aa94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;31m#Random lag generator - try to keep the code to be detected as a bot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mlag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;31m#Save the html of the listing link.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Code ready to scrape main listings and individual listings for 20 pages of 1 city --------------------------------------------------------------------------------\n",
    "\n",
    "#Dictionary for storage\n",
    "listings_dict = {'Price (usd)' : [], \"Address\" : [], 'Rooms' : [], 'Bathrooms' : [], 'Area (sqrt)' : [], 'Link' : [], \"typeProperty\" : [], \"yearBuilt\" : [], \"parking\" : [], \"lot\" : [], \"saleHistory\" : [], \"taxHistory\" : [] }\n",
    "\n",
    "#Path to drivers - need 2 browsers 1 for the main page listing and another for the individual links of each linsting.\n",
    "# If this is not done and we do everything in the same browser Zillow detects the crawler. \n",
    "# Remember to unzip the file of the drivers and get the absolute path to the driver not the relative path.\n",
    "#In the folder, copy the chrome driver and rename the copy as chromedriver2. Make sure browser is linked to chromedriver AND browser2 is linked to chromedriver2\n",
    "browser = webdriver.Chrome(\"\")\n",
    "browser2 = webdriver.Chrome(\"\")\n",
    "\n",
    "#starting page\n",
    "page = 1 \n",
    "\n",
    "#url to scrape starting at page 1\n",
    "url = \"https://www.zillow.com/homes/Austin,-TX_rb/\"\n",
    "\n",
    "#Open url -- We only want to open the browser once, so this is run outside the loop.\n",
    "browser.get(url)\n",
    "\n",
    "#while loop to iterate until condition is meet\n",
    "while True:\n",
    "\n",
    "    #Bot handler. -- Gives us 5 minutes to solve the human test and continues the code after it sees class = list-card-info.\n",
    "    try:\n",
    "        WebDriverWait(browser, 60*5).until(EC.presence_of_element_located((By.CLASS_NAME, \"list-card-info\")))\n",
    "    except:\n",
    "        print(\"Wait Timed out\")\n",
    "\n",
    "    \n",
    "\n",
    "    #Prints current page to scrape\n",
    "    print(f\"Current page: {page}\")\n",
    "\n",
    "    #Random lag generator - try to keep the code to be detected as a bot \n",
    "    lag = np.random.uniform(0, 2*60)\n",
    "    time.sleep(lag)\n",
    "\n",
    "    #save the html source of the main page.\n",
    "    html = browser.page_source\n",
    "\n",
    "    #Use bs4 to parse the html response.\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    #Results for all the listings in the page.\n",
    "    listings = soup.find_all('div', class_=\"list-card-info\")\n",
    "\n",
    "    #For loop to evaluate each listing per page\n",
    "    for listing in listings:\n",
    "\n",
    "        #page index counter\n",
    "        count = 0\n",
    "\n",
    "        #Defines each variable for each iteration\n",
    "        price = None \n",
    "        address = None \n",
    "        rooms = None \n",
    "        bathrooms = None \n",
    "        area = None \n",
    "        link = None \n",
    "        typeProperty = None \n",
    "        yearBuilt = None \n",
    "        parking = None \n",
    "        lot = None \n",
    "        saleHistory = None \n",
    "        taxHistory = None\n",
    "\n",
    "        #Try the main page.\n",
    "        try:\n",
    "            #Price of the property\n",
    "            try:\n",
    "                price = int(listing.find('div', class_=\"list-card-price\").text.replace(\"$\",\"\").replace(\",\",\"\"))\n",
    "            except ValueError as e:\n",
    "                print(f\"{e} error at price at {count}\")\n",
    "\n",
    "            #Address\n",
    "            try:\n",
    "                address = listing.find('address', class_=\"list-card-addr\").text\n",
    "            except ValueError as e:\n",
    "                print(f\"{e} error at address at {count}\")\n",
    "\n",
    "            #Rooms  - some are listed as Studio, bds and bd\n",
    "            try:\n",
    "                try:\n",
    "                    rooms = int(listing.find_all('li')[0].text.replace(\" bds\",\"\"))\n",
    "                except ValueError as e:\n",
    "                    pass\n",
    "                try:\n",
    "                    rooms = int(listing.find_all('li')[0].text.replace(\"Studio\",\"1\"))\n",
    "                except ValueError as e:\n",
    "                    pass\n",
    "                try:\n",
    "                    rooms = int(listing.find_all('li')[0].text.replace(\" bd\",\"\"))\n",
    "                except ValueError as e:\n",
    "                    pass\n",
    "            except ValueError as e:\n",
    "                print(f\"{e} error at rooms at {count}\")\n",
    "\n",
    "            #Bathrooms\n",
    "            try:\n",
    "                bathrooms = int(listing.find_all('li')[1].text.replace(\" ba\",\"\"))\n",
    "            except ValueError:\n",
    "                if (listing.find_all('li')[1].text == '-- ba'):\n",
    "                    continue\n",
    "\n",
    "            #Area of the house.\n",
    "            try:\n",
    "                area = int(listing.find_all('li')[2].text.replace(\" sqft\",\"\").replace(\",\",\"\"))\n",
    "            except ValueError as e:\n",
    "                print(f\"{e} error at area at {count}\")\n",
    "\n",
    "            #link of the individual listing.\n",
    "            try:\n",
    "                link = listing.a['href']\n",
    "            except ValueError as e:\n",
    "                print(f\"{e} error at rooms at {count}\")\n",
    "\n",
    "            #Opens the listing link using the second browser\n",
    "            browser2.get(link)\n",
    "\n",
    "            #Bot handler. -- Gives us 5 minutes to solve the human test and continues the code after it sees class = ds-body.\n",
    "            try:\n",
    "                WebDriverWait(browser2, 60*5).until(EC.presence_of_element_located((By.CLASS_NAME, \"ds-body\")))\n",
    "            except:\n",
    "                print(\"Wait Timed out\")\n",
    "\n",
    "            #Random lag generator - try to keep the code to be detected as a bot \n",
    "            lag = np.random.uniform(0, 3*60)\n",
    "            time.sleep(lag)\n",
    "\n",
    "            #Save the html of the listing link. \n",
    "            htmlink = browser2.page_source\n",
    "\n",
    "            #Use bs4 to parse the html response of the listing link\n",
    "            souplink = bs(htmlink, \"html.parser\")\n",
    "\n",
    "            #Type of property\n",
    "            try: \n",
    "                typeProperty = souplink.find_all('span', class_=\"ds-body ds-home-fact-value\")[0].text\n",
    "            except ValueError as e:\n",
    "                print(f\"{e}Error at type property at {link}\")\n",
    "            \n",
    "            #Year\n",
    "            try:\n",
    "                yearBuilt = int(souplink.find_all('span', class_=\"ds-body ds-home-fact-value\")[1].text)\n",
    "            except ValueError as e:\n",
    "                if (souplink.find_all('span', class_=\"ds-body ds-home-fact-value\")[1].text == 'No Data'):\n",
    "                    continue\n",
    "                print(f\"{e}Error at yearbuilt at {link}\")\n",
    "\n",
    "            #Parking - listed as spaces, space, detached garage, off street, carport\n",
    "            try:\n",
    "                try:\n",
    "                    parking = int(souplink.find_all('span', class_=\"ds-body ds-home-fact-value\")[4].text.replace(\" spaces\",\"\"))\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                try:\n",
    "                    parking = int(souplink.find_all('span', class_=\"ds-body ds-home-fact-value\")[4].text.replace(\" space\",\"\"))\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                try:\n",
    "                    parking = int(souplink.find_all('span', class_=\"ds-body ds-home-fact-value\")[4].text.replace(\"Detached Garage\",\"1\"))\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                try:\n",
    "                    parking = int(souplink.find_all('span', class_=\"ds-body ds-home-fact-value\")[4].text.replace(\"Off street\",\"1\"))\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                try:\n",
    "                    parking = int(souplink.find_all('span', class_=\"ds-body ds-home-fact-value\")[4].text.replace(\"Carport\",\"1\"))\n",
    "                except ValueError:\n",
    "                    pass\n",
    "            except ValueError as e:\n",
    "                print(f\"{e} garage error not determined at index {count}\")\n",
    "    \n",
    "            #Lot - if the house has HOW the listing will move. listed as sqft and acres.\n",
    "            try:\n",
    "                try: \n",
    "                    lot = int(souplink.find_all('span', class_=\"ds-body ds-home-fact-value\")[5].text.replace(\" sqft\",\"\").replace(\",\",\"\"))\n",
    "                except ValueError:\n",
    "                    pass \n",
    "                try:\n",
    "                    lot = int(souplink.find_all('span', class_=\"ds-body ds-home-fact-value\")[6].text.replace(\" sqft\",\"\").replace(\",\",\"\"))\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                try:\n",
    "                    lot = int(souplink.find_all('span', class_=\"ds-body ds-home-fact-value\")[5].text.replace(\" acres\",\"\").replace(\",\",\"\")) * 43560\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                try:\n",
    "                    lot = int(souplink.find_all('span', class_=\"ds-body ds-home-fact-value\")[6].text.replace(\" acres\",\"\").replace(\",\",\"\")) * 43560\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "            except (ValueError, IndexError) as e:\n",
    "                print(f\"{e} error at lot type at {link}\")\n",
    "\n",
    "            #Sale history\n",
    "            saleHistory = []\n",
    "            for i in souplink.find_all('td', class_=\"kaq65t-1 ijBExC\"):\n",
    "                try:\n",
    "                    saleHistory.append(i.find('span').text)\n",
    "                except AttributeError:\n",
    "                    continue \n",
    "\n",
    "            #tax history\n",
    "            taxHistory = []\n",
    "            for i in souplink.find_all('td', class_=\"kaq65t-1 eegcAA\"):\n",
    "                try:\n",
    "                    taxHistory.append(i.find('span').text)\n",
    "                except AttributeError:\n",
    "                    continue\n",
    "\n",
    "            #Only appends listings with complete information\n",
    "            if (price and address and rooms and bathrooms and area and link and typeProperty and yearBuilt and parking and lot and saleHistory and taxHistory):\n",
    "\n",
    "                listingInformation = [price, address, rooms, bathrooms, area, link, typeProperty, yearBuilt, parking, lot, saleHistory, taxHistory]\n",
    "\n",
    "                #For loop to append the scraped information.\n",
    "                for key,info in zip(listings_dict.keys(), listingInformation):\n",
    "                    listings_dict[key].append(info)\n",
    "\n",
    "            #Adds 1 to the count at the end of the listing scrape\n",
    "            count += 1\n",
    "            \n",
    "        except ValueError as e:\n",
    "            print(f\"{e} error at index {count} page {page}\")\n",
    "            count += 1\n",
    "\n",
    "    #Adds 1 to the page counter\n",
    "    page += 1\n",
    "\n",
    "    #Random lag generator - try to keep the code to be detected as a bot \n",
    "    lag = np.random.uniform(0, 1.5*60)\n",
    "    time.sleep(lag)\n",
    "\n",
    "    #Finds elements to go next page\n",
    "    nextpage = browser.find_element_by_css_selector(\"a.Button-wpcbcc-0.lcWnHB.PaginationButton-si2hz6-0.cUjspl\")\n",
    "\n",
    "    #Zillow only loads 20 page (500 listings) at  time.\n",
    "    if page <= 20:\n",
    "        #clicks next page.\n",
    "        nextpage.click()\n",
    "\n",
    "    else:\n",
    "        #When the code is done, this code kills the driver.\n",
    "        browser.quit()\n",
    "        browser2.quit()\n",
    "        print(\"Scape Done!!!!\")\n",
    "        break"
   ]
  }
 ]
}